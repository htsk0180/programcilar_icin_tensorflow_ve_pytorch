{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P0Br3Vfx7msu"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j0Bx3Oe7ms3"
      },
      "source": [
        "\n",
        "# nn.Transformer ve TorchText ile Dil Modelleme\n",
        "\n",
        "\n",
        "[nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html), [Attention](https://arxiv.org/pdf/1706.03762.pdf)_.\n",
        "Diziden diziye birçok görev için kalite açısından transformatör modeli Tekrarlayan Sinir Ağları (RNN'ler) ile karşılaştırıldığında kalite açısından üstün olduğu kanıtlanmıştır. Daha fazla paralelleştirilebilr olmaları bunu mümkün kılar. `nn.Transformer` modülü tamamen dikkat mekanizması üzerine kuruludur.\n",
        "[nn.MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html), \n",
        "[nn.TransformerEncoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html)_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAeoyy07ms9"
      },
      "source": [
        "## Modeli tanımlayalım\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zeb3KmmF7ms-"
      },
      "source": [
        " ``nn.TransformerEncoder`` modülünü dil modellemede kullanacağız. Dil modelleme görevi, belirli bir kelimenin (veya bir kelime dizisinin) olasılığı tahmin etmek için olasılıklar üretir.Bu işlem yapılırken kelime gömmeleri ve kelimelerin konumsal yerlerinin tespiti için konumsal bir katman eklenmesi gerekir.``nn.TransformerEncoder``\n",
        "[nn.TransformerEncoderLayer için linke tıklayabilirsiniz.](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jE9KJi907mtA"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnszkulC7mtD"
      },
      "source": [
        "``PosionalEncoding`` modülü, \n",
        "dizideki belirteçlerin göreli veya mutlak konumu hakkında bazı bilgiler enjekte eder. Bu\n",
        "konumsal kodlamalar, embeddings ile aynı boyuta sahiptir.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fNzcqoZz7mtG"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZC_d8Bi7mtH"
      },
      "source": [
        "## Load and batch data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm7TpXrH7mtJ"
      },
      "source": [
        "Wikitext-2 datasetini kullanacağız. Buna erişebilmemiz için torchtext modülüne ihtiyacımız var. Aynı zamanda eğer torcdata kurulu değilse pip install ile indirmemiz gerekecek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6ng3_vGy7mtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250b01be-b068-4c27-9ff7-a0d970999ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 46.2 MB/s eta 0:00:00\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchdata) (2.25.1)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchdata) (1.13.1+cu116)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata) (1.26.14)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->torchdata) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2.10)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install torchdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDa1m9H97mtM"
      },
      "source": [
        "Şimdi veri setimizdeki kelimeleri görseldeki mantığa göre hazırlamamız gerekir. Ve onları tensörlere çevirelim ki modelde kullanabilelim. Wikitext-2 içerisindeki bilinmeyen kelimer için de  `<unk>` kullanacağız.\n",
        "Sıralı bir vektör verildiğinde ( a-z arası sutüna sahip, görseldeki 1B vektör ) `batchify()` işlevi verileri `batch_size` da verilen değer kadar sütunlara böler. Eğer verileri eşit olarak bölemez ise veriler sığacak şekilde kırpılır. \n",
        "Örneğin toplam uzunluk 26 batch_size = 4 ise alfabe 6 uzunluğunda 4 parçaya ayrılır.\n",
        "\n",
        "\\begin{align}\\begin{bmatrix}\n",
        "  \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z}\n",
        "  \\end{bmatrix}\n",
        "  \\Rightarrow\n",
        "  \\begin{bmatrix}\n",
        "  \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} &\n",
        "  \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix}\n",
        "  \\end{bmatrix}\\end{align}\n",
        "\n",
        "Bu gruplama işlemi daha fazla paralelleştirilebilir işlem yapmamıza olanak sağlar. Model her sutünu bağımsız olarak ele alır. Örneğin, bağımlılığı\n",
        "yukarıdaki örnekte \"G\" ve \"F\" öğrenilemez.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HQQMe5vz7mtN"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>']) \n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgeRnSdp7mtO"
      },
      "source": [
        "### Girdi ve hedef dizisi oluşturma işlevleri\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzIx2GNT7mtP"
      },
      "source": [
        "get_batch(), transformatör modeli için bir çift giriş-hedef dizisi üretir.Kaynak verileri bptt uzunluğunda parçalara ayırır.. Dil modelleme görevi için, modelin Hedef olarak aşağıdaki kelimelere ihtiyacı vardır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cUqUDOCs7mtQ"
      },
      "outputs": [],
      "source": [
        "bptt = 35\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CumPJD-f7mtS"
      },
      "source": [
        "## Örnek başlatma \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlvg2ZYb7mtS"
      },
      "source": [
        "Model hiperparametreleri aşağıda tanımlanmıştır. kelime boyutu\n",
        "sözcük nesnesinin uzunluğuna eşittir.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F61cBETb7mtT"
      },
      "outputs": [],
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb0Dmlkp7mtU"
      },
      "source": [
        "## Modelimizi çalıştıralım.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hf_SwlN7mtV"
      },
      "source": [
        "[CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html),\n",
        "[SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html),\n",
        "[StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html),\n",
        "[nn.utils.clip_grad_norm](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html) bu belgeler modeli derlerken bize yardımcı olacaktır. Daha detaylı bilgi için linklere tıklayın.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OPkPcvDL7mtW"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSgFXtUY7mtX"
      },
      "source": [
        "Epoch'lardan sonra en iyi sonucu veren modeli kaydedelim ve lr ayarlamalarını planlanan şekilde yapalım.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y7xcnErx7mtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be4e898-b015-4d0d-8efe-319bfa9db308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 29.36 | loss  8.09 | ppl  3274.96\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 15.15 | loss  6.87 | ppl   963.64\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 19.70 | loss  6.44 | ppl   623.29\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 16.69 | loss  6.30 | ppl   541.86\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 14.26 | loss  6.18 | ppl   484.98\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 14.25 | loss  6.15 | ppl   469.32\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 14.49 | loss  6.10 | ppl   447.18\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 14.74 | loss  6.10 | ppl   447.08\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 14.34 | loss  6.01 | ppl   408.69\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 14.40 | loss  6.01 | ppl   408.38\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 14.48 | loss  5.89 | ppl   362.58\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 15.03 | loss  5.96 | ppl   389.48\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 14.56 | loss  5.94 | ppl   381.05\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 14.58 | loss  5.87 | ppl   355.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 48.88s | valid loss  5.81 | valid ppl   334.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 15.15 | loss  5.85 | ppl   348.34\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 14.78 | loss  5.84 | ppl   345.27\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 14.82 | loss  5.67 | ppl   289.31\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 14.83 | loss  5.70 | ppl   298.23\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 15.26 | loss  5.65 | ppl   284.00\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 14.95 | loss  5.68 | ppl   292.35\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 15.02 | loss  5.68 | ppl   294.05\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 15.00 | loss  5.71 | ppl   300.86\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 15.26 | loss  5.65 | ppl   283.56\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 14.91 | loss  5.67 | ppl   289.10\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 14.91 | loss  5.55 | ppl   257.19\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 14.87 | loss  5.64 | ppl   281.56\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 15.17 | loss  5.64 | ppl   281.83\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 14.78 | loss  5.58 | ppl   264.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 45.62s | valid loss  5.65 | valid ppl   282.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 15.67 | loss  5.60 | ppl   270.51\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 15.13 | loss  5.61 | ppl   273.24\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 14.68 | loss  5.42 | ppl   226.14\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 14.66 | loss  5.48 | ppl   240.42\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 14.65 | loss  5.44 | ppl   229.85\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 15.08 | loss  5.47 | ppl   238.27\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 14.66 | loss  5.49 | ppl   242.86\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 14.63 | loss  5.51 | ppl   248.38\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 14.65 | loss  5.47 | ppl   236.55\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 15.04 | loss  5.49 | ppl   241.17\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 14.79 | loss  5.36 | ppl   212.29\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 14.68 | loss  5.46 | ppl   235.18\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 14.69 | loss  5.47 | ppl   237.89\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 14.96 | loss  5.41 | ppl   223.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 45.30s | valid loss  5.54 | valid ppl   255.84\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deGEJiTc7mtY"
      },
      "source": [
        "## Test veri kümesiyle en iyi modeli değerlendirin\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YXcj9Vzq7mtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9271518-91cc-4464-e2f6-69dd732becbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.45 | test ppl   233.27\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "test_loss = evaluate(model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('=' * 89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('=' * 89)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}