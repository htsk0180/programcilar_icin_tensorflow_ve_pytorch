{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Azo3sM31PbA5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x_aAzz1PbBF"
      },
      "source": [
        "\n",
        "# Dağıtım için Vision Transformer Modelini Optimize Etme\n",
        "\n",
        "[DeiT](https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification)\n",
        "Görüntü sınıflandırma için ImageNet üzerinde eğitilmiş bir Vision Transformer modelidir.\n",
        "\n",
        "Bu eğitimde, öncelikle DeiT'nin ne olduğunu ve nasıl kullanılacağını ele alacağız,\n",
        "sonra komut dosyası oluşturma, niceleme, optimize etme adımlarının tamamını uygulayacağız,\n",
        "ve modeli iOS ve Android uygulamalarında nasıl kullanacağımıza bakacağız. Kuantize edilmiş, optimize edilmiş ve kuantize edilmemiş, optimize edilmemiş model performanslarını karşılaştıracağız.\n",
        "Faydalarını göreceğiz.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm-ynyvrPbBK"
      },
      "source": [
        "## DeiT tam olarak nedir?\n",
        "\n",
        "Evrişimli Sinir Ağları (CNN'ler), görü için ana modeller olmuştur.\n",
        "2012'de derin öğrenme başladığından beri sınıflandırma problemlerinde temel olarak kullanılmıştır. Ancak CNN'ler\n",
        "eğitim için yüz milyonlarca görüntüye ihtiyaç duyar.\n",
        "`DeiT`, çok daha azını gerektiren bir görüntü dönüştürme modelidir.\n",
        "Başarımı kanıtlanmış CNN mimarileriyle rekabet etmek için gereken eğitim/test verisi ve bilgi işlem kaynaklarının daha azına ihtiyaç duyar.\n",
        "DeiT'nin temel bileşenleri:\n",
        "\n",
        "-  Eğitimi çok daha büyük bir veri kümesinde simüle eden veri artırma;\n",
        "-  Transformer network ağını öğrenen yerel bir CNN çıktısı.\n",
        "\n",
        "`DeiT`, Transformers'ın bilgisayarlı görü problemlerine başarıyla uygulanabileceğini gösteriyor\n",
        "Eğer veri ve kaynaklara sınırlı erişim var ise. Daha fazlası için\n",
        "DeiT ile ilgili ayrıntılar burada [repo](https://github.com/facebookresearch/deit)\n",
        "ve [makale](https://arxiv.org/abs/2012.12877).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18rIhDHPbBN"
      },
      "source": [
        "## DeiT ile görüntü sınıflandırma\n",
        "\n",
        "DebiT kullanarak görüntülerin nasıl sınıflandırılacağına ilişkin ayrıntılı bilgi için DieT deposundaki BENİOKU'yu takip edin veya hızlı bir test için önce gerekli paketleri kurun:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RebASiJJPbBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8093852-1fc9-45a9-91f7-37540e9af93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.12.1 timm-0.6.12\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision timm pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5XfKMpb2PbBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3729d73-7450-44cc-a954-f8b2eb48e35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.25.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.1+cu116)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.12.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4G5B5JzyPbBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "95b34616f5e44e779b290b5571fbe138",
            "29b85e62d0c643f4a043d810a4625de2",
            "87d2908009464bfe948a93cb94c71755",
            "550b7afd7e4b4857a851ba43981ec397",
            "de57a85bd91d4852a9ae20877e447dc0",
            "ceccc533f263408aa6dbaa8f90f5cf2d",
            "9eb1edc033b54d5f9a6d5ed8eeb1962b",
            "a46a68a3d0f04ab78c5697da7ecda306",
            "1c7c67658e1b472c88fc2c987efa86cc",
            "b40efc2484d54810b677b9ea46020a06",
            "8378662bfea84a8d972cd94e3340a710"
          ]
        },
        "outputId": "3cd5624f-022f-435c-b0f7-f3924fe5bab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/330M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95b34616f5e44e779b290b5571fbe138"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import timm\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "print(torch.__version__)\n",
        "# should be 1.8.0\n",
        "\n",
        "\n",
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=3),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
        "])\n",
        "\n",
        "img = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\n",
        "img = transform(img)[None,]\n",
        "out = model(img)\n",
        "clsidx = torch.argmax(out)\n",
        "print(clsidx.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iPz9rf2PbBY"
      },
      "source": [
        "Artık sınıflandırmak için DeiT modelini kullanabileceğimizi doğruladığımıza göre\n",
        "şimdi modelin iOS ve Android de çalışabilmesi için nasıl değiştirileceğini görelim.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ldQEWRPbBZ"
      },
      "source": [
        "## DeiT Komut dosyası\n",
        "Modeli mobilde kullanmak için öncelikle şu komut dosyasını yazmamız gerekiyor:\n",
        "modeli. [Komut Dosyası ve Optimize](https://pytorch.org/tutorials/recipes/script_optimized.html) bakın.\n",
        "Kullanılan DeiT modelini dönüştürmek için aşağıdaki kodu çalıştırın.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5j5EsPPJPbBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c83710-8e04-4085-8827-44694456eaf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "model.eval()\n",
        "scripted_model = torch.jit.script(model)\n",
        "scripted_model.save(\"fbdeit_scripted.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjAHtU3nPbBc"
      },
      "source": [
        "Yaklaşık 346 MB boyutunda betikli model dosyasını fbdeit_scripted.pt\n",
        "adı altında oluşturduk.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQnDzQagPbBd"
      },
      "source": [
        "## Quantizing DeiT\n",
        "Eğitimli model boyutunu ( 346 MB'lık fbdeit_scripted.pt model dosyamızı ) önemli ölçüde azaltmak için\n",
        "çıkarım doğruluğunu yaklaşık olarak aynı tutarak, niceleme\n",
        "modele uygulanır. DeiT'de kullanılan transformer modeli sayesinde\n",
        "dinamik nicelemeyi modele kolayca uygulayabiliriz, çünkü dinamik\n",
        "niceleme en iyi LSTM ve transformatör modelleri için çalışır ([ konu hakkında daha fazla bilgi için buraya bakın] (https://pytorch.org/docs/stable/quantization.html?highlight=quantization#dynamic-quantization).\n",
        "\n",
        "Şimdi aşağıdaki kodu çalıştırın:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5-zaRzKoPbBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3edde3c-24f0-4eef-8557-fd15f8cbafb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Sunucu çıkarımı için \"fbgemm\" ve mobil çıkarım için \"qnnpack\" kullanın\n",
        "backend = \"fbgemm\" # qnnpack ile değiştirildi, bu dizüstü bilgisayarda sayısallaştırılmış model için çok daha kötü çıkarım hızına neden oluyor\n",
        "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
        "torch.backends.quantized.engine = backend\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n",
        "scripted_quantized_model = torch.jit.script(quantized_model)\n",
        "scripted_quantized_model.save(\"fbdeit_scripted_quantized.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nxOc3JJPbBg"
      },
      "source": [
        "Aynısını oluşturmak için ``scripted_quantized_model`` kullanabilirsiniz.\n",
        "çıkarım sonucu:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nfBWv276PbBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c6e83b-be26-4511-d7cf-4bad9beb7118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269\n"
          ]
        }
      ],
      "source": [
        "out = scripted_quantized_model(img)\n",
        "clsidx = torch.argmax(out)\n",
        "print(clsidx.item())\n",
        "# The same output 269 should be printed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0BcItC2PbBh"
      },
      "source": [
        "## DeiT'i optimize etme\n",
        "Kuantize edilmiş ve kodlanmış olanı kullanmadan önceki son adım\n",
        "mobil cihazdaki modeli optimize etmektir.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6acbnUXMPbBh"
      },
      "outputs": [],
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n",
        "optimized_scripted_quantized_model.save(\"fbdeit_optimized_scripted_quantized.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ZsbACPPbBi"
      },
      "source": [
        "Oluşturulan fbdeit_optimized_scripted_quantized.pt dosyası, sayısallaştırılmış, kodlanmış, ancak optimize edilmemiş modelle yaklaşık olarak aynı boyuta sahiptir. Çıkarım sonucu aynı kalır.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PK33io1-PbBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8788af19-5a2d-459f-ecee-72f86a7764fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269\n"
          ]
        }
      ],
      "source": [
        "out = optimized_scripted_quantized_model(img)\n",
        "clsidx = torch.argmax(out)\n",
        "print(clsidx.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovA69AHPbBk"
      },
      "source": [
        "## Lite Interpreter Kullanımı\n",
        "\n",
        "Model boyutu küçültme ve çıkarımın Lite'ı ne kadar hızlandırdığını görmek için modelin lite sürümünü oluşturalım.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YQr8HC4WPbBl"
      },
      "outputs": [],
      "source": [
        "optimized_scripted_quantized_model._save_for_lite_interpreter(\"fbdeit_optimized_scripted_quantized_lite.ptl\")\n",
        "ptl = torch.jit.load(\"fbdeit_optimized_scripted_quantized_lite.ptl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WiECGJ7PbBm"
      },
      "source": [
        "Lite model boyutu, lite olmayan sürümle karşılaştırılabilir olsa da, lite sürümünü mobilde çalıştırırken, çıkarım hızının artması beklenir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HL9UIhrPbBn"
      },
      "source": [
        "## Çıkarım Hızını Karşılaştırma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ld9MiBPGPbBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c926675-152e-48b8-b0ec-d9abf83e1e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original model: 765.54ms\n",
            "scripted model: 700.83ms\n",
            "scripted & quantized model: 650.25ms\n",
            "scripted & quantized & optimized model: 519.33ms\n",
            "lite model: 709.41ms\n"
          ]
        }
      ],
      "source": [
        "with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n",
        "    out = model(img)\n",
        "with torch.autograd.profiler.profile(use_cuda=False) as prof2:\n",
        "    out = scripted_model(img)\n",
        "with torch.autograd.profiler.profile(use_cuda=False) as prof3:\n",
        "    out = scripted_quantized_model(img)\n",
        "with torch.autograd.profiler.profile(use_cuda=False) as prof4:\n",
        "    out = optimized_scripted_quantized_model(img)\n",
        "with torch.autograd.profiler.profile(use_cuda=False) as prof5:\n",
        "    out = ptl(img)\n",
        "\n",
        "print(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\n",
        "print(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\n",
        "print(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\n",
        "print(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\n",
        "print(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omh3Y5x6PbBp"
      },
      "source": [
        "The following results summarize the inference time taken by each model\n",
        "and the percentage reduction of each model relative to the original\n",
        "model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kp1xPb7SPbBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "e54f7c6e-2e98-4af3-fae5-8178a96c5972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    Model Çıkarım Süresi Kesinti\n",
            "0                          original model       765.54ms      0%\n",
            "1                          scripted model       700.83ms   8.45%\n",
            "2              scripted & quantized model       650.25ms  15.06%\n",
            "3  scripted & quantized & optimized model       519.33ms  32.16%\n",
            "4                              lite model       709.41ms   7.33%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n        Model                             Çıkarım Süresi    Kesinti\\n0\\toriginal model                             1236.69ms           0%\\n1\\tscripted model                             1226.72ms        0.81%\\n2\\tscripted & quantized model                  593.19ms       52.03%\\n3\\tscripted & quantized & optimized model      598.01ms       51.64%\\n4\\tlite model                                  600.72ms       51.43%\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame({'Model': ['original model','scripted model', 'scripted & quantized model', 'scripted & quantized & optimized model', 'lite model']})\n",
        "df = pd.concat([df, pd.DataFrame([\n",
        "    [\"{:.2f}ms\".format(prof1.self_cpu_time_total/1000), \"0%\"],\n",
        "    [\"{:.2f}ms\".format(prof2.self_cpu_time_total/1000),\n",
        "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof2.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
        "    [\"{:.2f}ms\".format(prof3.self_cpu_time_total/1000),\n",
        "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof3.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
        "    [\"{:.2f}ms\".format(prof4.self_cpu_time_total/1000),\n",
        "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof4.self_cpu_time_total)/prof1.self_cpu_time_total*100)],\n",
        "    [\"{:.2f}ms\".format(prof5.self_cpu_time_total/1000),\n",
        "     \"{:.2f}%\".format((prof1.self_cpu_time_total-prof5.self_cpu_time_total)/prof1.self_cpu_time_total*100)]],\n",
        "    columns=['Çıkarım Süresi', 'Kesinti'])], axis=1)\n",
        "\n",
        "print(df)\n",
        "\n",
        "\"\"\"\n",
        "        Model                             Çıkarım Süresi    Kesinti\n",
        "0\toriginal model                             1236.69ms           0%\n",
        "1\tscripted model                             1226.72ms        0.81%\n",
        "2\tscripted & quantized model                  593.19ms       52.03%\n",
        "3\tscripted & quantized & optimized model      598.01ms       51.64%\n",
        "4\tlite model                                  600.72ms       51.43%\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ65SRLjPbBr"
      },
      "source": [
        "### Daha fazlası için\n",
        "\n",
        "- [Facebook Data-efficient Image Transformers](https://ai.facebook.com/blog/data-efficient-image-transformers-a-promising-new-technique-for-image-classification)_\n",
        "- [Vision Transformer with ImageNet and MNIST on iOS](https://github.com/pytorch/ios-demo-app/tree/master/ViT4MNIST)_\n",
        "- [Vision Transformer with ImageNet and MNIST on Android](https://github.com/pytorch/android-demo-app/tree/master/ViT4MNIST)_\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95b34616f5e44e779b290b5571fbe138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29b85e62d0c643f4a043d810a4625de2",
              "IPY_MODEL_87d2908009464bfe948a93cb94c71755",
              "IPY_MODEL_550b7afd7e4b4857a851ba43981ec397"
            ],
            "layout": "IPY_MODEL_de57a85bd91d4852a9ae20877e447dc0"
          }
        },
        "29b85e62d0c643f4a043d810a4625de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceccc533f263408aa6dbaa8f90f5cf2d",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb1edc033b54d5f9a6d5ed8eeb1962b",
            "value": "100%"
          }
        },
        "87d2908009464bfe948a93cb94c71755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46a68a3d0f04ab78c5697da7ecda306",
            "max": 346319111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c7c67658e1b472c88fc2c987efa86cc",
            "value": 346319111
          }
        },
        "550b7afd7e4b4857a851ba43981ec397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40efc2484d54810b677b9ea46020a06",
            "placeholder": "​",
            "style": "IPY_MODEL_8378662bfea84a8d972cd94e3340a710",
            "value": " 330M/330M [00:25&lt;00:00, 24.8MB/s]"
          }
        },
        "de57a85bd91d4852a9ae20877e447dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceccc533f263408aa6dbaa8f90f5cf2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb1edc033b54d5f9a6d5ed8eeb1962b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a46a68a3d0f04ab78c5697da7ecda306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c7c67658e1b472c88fc2c987efa86cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b40efc2484d54810b677b9ea46020a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8378662bfea84a8d972cd94e3340a710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}